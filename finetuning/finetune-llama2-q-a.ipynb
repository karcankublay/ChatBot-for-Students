{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7045374,"sourceType":"datasetVersion","datasetId":4054084}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n%pip install accelerate peft bitsandbytes transformers trl datasets==2.16.0","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:33:58.187617Z","iopub.execute_input":"2023-12-30T04:33:58.18798Z","iopub.status.idle":"2023-12-30T04:34:18.996857Z","shell.execute_reply.started":"2023-12-30T04:33:58.187951Z","shell.execute_reply":"2023-12-30T04:34:18.99532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nimport bitsandbytes as bnb\nfrom sklearn.model_selection import train_test_split\nfrom peft import LoraConfig, PeftConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\nimport pandas as pd\nfrom trl import SFTTrainer","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:34:18.999404Z","iopub.execute_input":"2023-12-30T04:34:19.002851Z","iopub.status.idle":"2023-12-30T04:34:39.517984Z","shell.execute_reply.started":"2023-12-30T04:34:19.002813Z","shell.execute_reply":"2023-12-30T04:34:39.516973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/comprehensive-medical-q-a-dataset/train.csv')\ndataset = dataset.drop('qtype', axis=1)\ndataset = dataset.rename(columns={'Question': 'question', 'Answer': 'answer'})","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:34:39.519144Z","iopub.execute_input":"2023-12-30T04:34:39.519417Z","iopub.status.idle":"2023-12-30T04:34:39.966049Z","shell.execute_reply.started":"2023-12-30T04:34:39.519393Z","shell.execute_reply":"2023-12-30T04:34:39.965131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_full_train, df_test = train_test_split(dataset, test_size=0.2, random_state=56)\ndf_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=56)","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:34:39.96725Z","iopub.execute_input":"2023-12-30T04:34:39.967593Z","iopub.status.idle":"2023-12-30T04:34:39.978205Z","shell.execute_reply.started":"2023-12-30T04:34:39.967565Z","shell.execute_reply":"2023-12-30T04:34:39.977334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.reset_index(drop=True)\ndf_val = df_train.reset_index(drop=True)\ndf_test = df_train.reset_index(drop=True)\n\ntrain_dataset = Dataset.from_pandas(df_train)\nval_dataset = Dataset.from_pandas(df_val)\ntest_dataset = Dataset.from_pandas(df_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:34:39.981826Z","iopub.execute_input":"2023-12-30T04:34:39.982184Z","iopub.status.idle":"2023-12-30T04:34:40.883088Z","shell.execute_reply.started":"2023-12-30T04:34:39.98215Z","shell.execute_reply":"2023-12-30T04:34:40.882087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"health_dataset_dict = DatasetDict({\n    'train': train_dataset,\n    'validation': val_dataset,\n    'test': test_dataset\n})","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:34:40.884571Z","iopub.execute_input":"2023-12-30T04:34:40.884946Z","iopub.status.idle":"2023-12-30T04:34:40.890526Z","shell.execute_reply.started":"2023-12-30T04:34:40.884912Z","shell.execute_reply":"2023-12-30T04:34:40.889451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to transform the data\ndef transform_conversation(example):\n    conversation_text = example['question']\n    conversation_answer = example['answer']\n\n    reformatted_segments = []\n    \n    if conversation_answer:\n        reformatted_segments.append(f'<s>[INST] {conversation_text} [/INST] {conversation_answer} </s>')\n        \n    else:\n        reformatted_segments.append(f'<s>[INST] {conversation_text} [/INST] </s>')\n    return {'text': ''.join(reformatted_segments)}","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:34:40.891597Z","iopub.execute_input":"2023-12-30T04:34:40.891858Z","iopub.status.idle":"2023-12-30T04:34:40.900501Z","shell.execute_reply.started":"2023-12-30T04:34:40.891835Z","shell.execute_reply":"2023-12-30T04:34:40.89973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformed_dataset = health_dataset_dict.map(transform_conversation)\ntransformed_dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:34:40.901597Z","iopub.execute_input":"2023-12-30T04:34:40.901837Z","iopub.status.idle":"2023-12-30T04:34:42.916014Z","shell.execute_reply.started":"2023-12-30T04:34:40.901816Z","shell.execute_reply":"2023-12-30T04:34:42.915009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model from Hugging Face hub\nbase_model = \"NousResearch/Llama-2-7b-chat-hf\"\n\n# Fine-tuned model\nnew_model = \"llama-2-7b-chat-health\"","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:34:42.917171Z","iopub.execute_input":"2023-12-30T04:34:42.917432Z","iopub.status.idle":"2023-12-30T04:34:42.921977Z","shell.execute_reply.started":"2023-12-30T04:34:42.917409Z","shell.execute_reply":"2023-12-30T04:34:42.921006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compute_dtype = getattr(torch, \"float16\")\n\nquant_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:34:42.923347Z","iopub.execute_input":"2023-12-30T04:34:42.923682Z","iopub.status.idle":"2023-12-30T04:34:42.94342Z","shell.execute_reply.started":"2023-12-30T04:34:42.923656Z","shell.execute_reply":"2023-12-30T04:34:42.94252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    device_map=\"auto\",\n    trust_remote_code=True,\n    quantization_config=quant_config\n)\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:34:42.944704Z","iopub.execute_input":"2023-12-30T04:34:42.945041Z","iopub.status.idle":"2023-12-30T04:36:50.826922Z","shell.execute_reply.started":"2023-12-30T04:34:42.945009Z","shell.execute_reply":"2023-12-30T04:36:50.825974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:36:50.828058Z","iopub.execute_input":"2023-12-30T04:36:50.828354Z","iopub.status.idle":"2023-12-30T04:36:51.768227Z","shell.execute_reply.started":"2023-12-30T04:36:50.828328Z","shell.execute_reply":"2023-12-30T04:36:51.767458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = prepare_model_for_kbit_training(model)","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:36:51.769572Z","iopub.execute_input":"2023-12-30T04:36:51.77018Z","iopub.status.idle":"2023-12-30T04:36:51.786217Z","shell.execute_reply.started":"2023-12-30T04:36:51.770146Z","shell.execute_reply":"2023-12-30T04:36:51.785503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"peft_params = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.05,\n    r=2,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:36:51.79012Z","iopub.execute_input":"2023-12-30T04:36:51.790629Z","iopub.status.idle":"2023-12-30T04:36:51.794822Z","shell.execute_reply.started":"2023-12-30T04:36:51.790603Z","shell.execute_reply":"2023-12-30T04:36:51.793897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_params = TrainingArguments(\n    output_dir=\"/kaggle/working/results\",\n    num_train_epochs=1,\n    per_device_train_batch_size=8,\n    gradient_accumulation_steps=4,\n    optim=\"paged_adamw_32bit\",\n    save_steps=25,\n    logging_steps=25,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    fp16=False,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    lr_scheduler_type=\"constant\",\n    report_to=\"tensorboard\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:37:29.944031Z","iopub.execute_input":"2023-12-30T04:37:29.944813Z","iopub.status.idle":"2023-12-30T04:37:29.951829Z","shell.execute_reply.started":"2023-12-30T04:37:29.944777Z","shell.execute_reply":"2023-12-30T04:37:29.950696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=transformed_dataset['train'],\n    peft_config=peft_params,\n    dataset_text_field=\"text\",\n    max_seq_length=None,\n    tokenizer=tokenizer,\n    args=training_params,\n    packing=False,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:37:32.657527Z","iopub.execute_input":"2023-12-30T04:37:32.658456Z","iopub.status.idle":"2023-12-30T04:37:38.456989Z","shell.execute_reply.started":"2023-12-30T04:37:32.658412Z","shell.execute_reply":"2023-12-30T04:37:38.456046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Free GPU memory\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:37:40.783994Z","iopub.execute_input":"2023-12-30T04:37:40.784389Z","iopub.status.idle":"2023-12-30T04:37:40.789619Z","shell.execute_reply.started":"2023-12-30T04:37:40.784353Z","shell.execute_reply":"2023-12-30T04:37:40.788535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Training is starting.....')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model\ntrainer.train()\n\n# Save trained model\ntrainer.model.save_pretrained(new_model)\ntrainer.tokenizer.save_pretrained(new_model)","metadata":{"execution":{"iopub.status.busy":"2023-12-30T04:37:42.544325Z","iopub.execute_input":"2023-12-30T04:37:42.544876Z","iopub.status.idle":"2023-12-30T04:39:02.137212Z","shell.execute_reply.started":"2023-12-30T04:37:42.544827Z","shell.execute_reply":"2023-12-30T04:39:02.135895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"What is bacteria?\"\npipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\nresult = pipe(f\"<s>[INST] {prompt} [/INST]\")\nprint(result[0]['generated_text'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}